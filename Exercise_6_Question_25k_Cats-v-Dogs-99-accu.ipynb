{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 6 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kd303/tensorflow_coursera/blob/master/Exercise_6_Question_25k_Cats-v-Dogs-99-accu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn-6c02VmqiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n",
        "# This will require you doing a lot of data preprocessing because\n",
        "# the dataset isn't split into training and validation for you\n",
        "# This code block has all the required inputs\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sd9dQWa23aj",
        "colab_type": "code",
        "outputId": "4163cb3c-2554-4cbc-ba8f-261727bbfa19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# This code block downloads the full Cats-v-Dogs dataset and stores it as \n",
        "# cats-and-dogs.zip. It then unzips it to /tmp\n",
        "# which will create a tmp/PetImages directory containing subdirectories\n",
        "# called 'Cat' and 'Dog' (that's how the original researchers structured it)\n",
        "# If the URL doesn't work, \n",
        "# .   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-07 04:29:19--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 104.74.20.142, 2600:140e:6:7b2::e59, 2600:140e:6:787::e59, ...\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|104.74.20.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M  12.5MB/s    in 64s     \n",
            "\n",
            "2019-08-07 04:30:23 (12.3 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi3yD62a6X3S",
        "colab_type": "code",
        "outputId": "0ba02b43-d759-4f2d-f828-9304ce233aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
        "\n",
        "# Expected Output:\n",
        "# 12501\n",
        "# 12501"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12501\n",
            "12501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-QkLjxpmyK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use os.mkdir to create your directories\n",
        "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
        "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
        "try:\n",
        "    #YOUR CODE GOES HERE\n",
        "    os.mkdir(\"/tmp/cats-v-dogs\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training/cats\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/training/dogs\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/testing\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/testing/cats\")\n",
        "    os.mkdir(\"/tmp/cats-v-dogs/testing/dogs\")\n",
        "except OSError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSODo0f9LaU",
        "colab_type": "code",
        "outputId": "7d60fd87-dd34-4bf8-d345-dcd34b183a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Write a python function called split_data which takes\n",
        "# a SOURCE directory containing the files\n",
        "# a TRAINING directory that a portion of the files will be copied to\n",
        "# a TESTING directory that a portion of the files will be copie to\n",
        "# a SPLIT SIZE to determine the portion\n",
        "# The files should also be randomized, so that the training set is a random\n",
        "# X% of the files, and the test set is the remaining files\n",
        "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
        "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
        "# and 10% of the images will be copied to the TESTING dir\n",
        "# Also -- All images should be checked, and if they have a zero file length,\n",
        "# they will not be copied over\n",
        "#\n",
        "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
        "# os.path.getsize(PATH) gives you the size of the file\n",
        "# copyfile(source, destination) copies a file from source to destination\n",
        "# random.sample(list, len(list)) shuffles a list\n",
        "\n",
        "def copy_nonzero_files(filenames, TARGET, SOURCE):\n",
        "  for filename in filenames:\n",
        "    fpath = os.path.join(SOURCE, filename)\n",
        "    if os.path.getsize(fpath) > 0:\n",
        "      copyfile(fpath, os.path.join(TARGET, filename))\n",
        "    else:\n",
        "      print(\" Ignoring file \"+fpath+\" since the size is zero\")\n",
        "\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "# YOUR CODE STARTS HERE\n",
        "  srcfiles = os.listdir(SOURCE)\n",
        "  srcfiles = random.sample(srcfiles, len(srcfiles))\n",
        "  train_lst_size = int(len(srcfiles)*SPLIT_SIZE)\n",
        "  training_file_list = srcfiles[:train_lst_size]\n",
        "  testing_file_list = srcfiles[train_lst_size:]\n",
        "  #print(train_lst_size)\n",
        "  #print(SOURCE +\" Size of training : \"+str(len(training_file_list))+\" & testing  : \"+str(len(testing_file_list)))\n",
        "  copy_nonzero_files(training_file_list, TRAINING, SOURCE)\n",
        "  copy_nonzero_files(testing_file_list, TESTING, SOURCE)\n",
        "# YOUR CODE ENDS HERE\n",
        "\n",
        "# YOUR CODE STARTS HERE\n",
        "# YOUR CODE ENDS HERE\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Ignoring file /tmp/PetImages/Cat/666.jpg since the size is zero\n",
            " Ignoring file /tmp/PetImages/Dog/11702.jpg since the size is zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luthalB76ufC",
        "colab_type": "code",
        "outputId": "baa7cae5-e5c4-4297-e360-fe54ac12d259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11250\n",
            "11249\n",
            "1250\n",
            "1251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BQrav4anTmj",
        "colab_type": "code",
        "outputId": "042168fb-4573-46a0-9aa6-aa6a160a14c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "# USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "model = tf.keras.models.Sequential([\n",
        "# YOUR CODE HERE\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300,300,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 04:37:22.073470 140273718126464 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0807 04:37:22.342465 140273718126464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               8389120   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 8,450,145\n",
            "Trainable params: 8,450,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlNjoJ5D61N6",
        "colab_type": "code",
        "outputId": "f1328dcc-97c1-4aa3-8741-254895c26fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TRAINING_DIR = '/tmp/cats-v-dogs/training'  #YOUR CODE HERE\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               width_shift_range=0.2,\n",
        "                               height_shift_range=0.2,\n",
        "                               fill_mode='nearest',\n",
        "                               rotation_range=0.4,\n",
        "                               horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, target_size=(300,300),\n",
        "                                                   batch_size=64,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "VALIDATION_DIR = '/tmp/cats-v-dogs/testing' #YOUR CODE HERE\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, target_size=(300,300),\n",
        "                                                              batch_size=64,\n",
        "                                                             class_mode='binary')\n",
        "\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22497 images belonging to 2 classes.\n",
            "Found 2501 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8TekCjX2r1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /tmp/trained_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqeGyNpv2Ww6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# epoch number is included in the path\n",
        "checkpoint_path = \"/tmp/trained_model/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "ckp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only = True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyS4n53w7DxC",
        "colab_type": "code",
        "outputId": "d8e72d17-5f03-4a65-f381-246a3ffd07af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=15,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator, callbacks=[ckp_callback])\n",
        "\n",
        "# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\n",
        "# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "  7/352 [..............................] - ETA: 8:08 - loss: 0.1337 - acc: 0.9442"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 80000 bytes but only got 0. Skipping tag 64640\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307363840 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 307888128 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 328728576 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 5357. Skipping tag 513\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 5357. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "201/352 [================>.............] - ETA: 3:27 - loss: 0.1427 - acc: 0.9416"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404094976 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 404619264 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 425459712 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1385474 bytes but only got 6833. Skipping tag 513\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 196867 bytes but only got 6833. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "245/352 [===================>..........] - ETA: 2:27 - loss: 0.1443 - acc: 0.9408"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 18350080 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 6. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "312/352 [=========================>....] - ETA: 54s - loss: 0.1428 - acc: 0.9407"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6553600 bytes but only got 0. Skipping tag 49\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 4951. Skipping tag 51\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293339136 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 293863424 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3368026112 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 134479872 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 295698432 bytes but only got 0. Skipping tag 10\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 296222720 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14745600 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25624576 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 317718528 bytes but only got 4956. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 4952. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 393216 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287178752 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 287703040 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 524288 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 286654464 bytes but only got 4956. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "325/352 [==========================>...] - ETA: 37s - loss: 0.1417 - acc: 0.9412"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "347/352 [============================>.] - ETA: 6s - loss: 0.1414 - acc: 0.9414"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 209715200 bytes but only got 0. Skipping tag 48\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 52428800 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6468665344 bytes but only got 0. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 1050744 bytes but only got 7027. Skipping tag 48\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 422313984 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 422838272 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 428867584 bytes but only got 0. Skipping tag 10\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 429391872 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2031616 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 429916160 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 21299200 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 24313856 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 453771264 bytes but only got 7032. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131073 bytes but only got 7028. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 416415744 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 416940032 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 415825920 bytes but only got 7032. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "351/352 [============================>.] - ETA: 1s - loss: 0.1416 - acc: 0.9412"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262146 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262151 bytes but only got 0. Skipping tag 56\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r352/352 [==============================] - 498s 1s/step - loss: 0.1417 - acc: 0.9411 - val_loss: 0.1182 - val_acc: 0.9500\n",
            "Epoch 2/15\n",
            "352/352 [==============================] - 483s 1s/step - loss: 0.1321 - acc: 0.9463 - val_loss: 0.1396 - val_acc: 0.9420\n",
            "Epoch 3/15\n",
            " 69/352 [====>.........................] - ETA: 5:47 - loss: 0.1559 - acc: 0.9339"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IBMSltcQSV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/tmp/dogs-v-cats.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZrJN4-65RC",
        "colab_type": "code",
        "outputId": "50f8ce0a-42e5-49a1-f3f2-7f2533d463b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "# PLOT LOSS AND ACCURACY\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAEICAYAAAAwft9dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEICAYAAADV4BoxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh5mZmWXPYWZmZtlzmJmZWfb+DyJeXRoRVBzbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqL6FYUrtXpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here's a codeblock just for fun. You should be able to upload an image here \n",
        "# and have it classified without crashing\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(# YOUR CODE HERE))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}